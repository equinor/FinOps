{
	"name": "cost-extend-utilities",
	"properties": {
		"folder": {
			"name": "NotebookInProduction/Cost Extension"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "sprkpool33large",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "112g",
			"driverCores": 16,
			"executorMemory": "112g",
			"executorCores": 16,
			"numExecutors": 1,
			"conf": {
				"spark.dynamicAllocation.enabled": "true",
				"spark.dynamicAllocation.minExecutors": "1",
				"spark.dynamicAllocation.maxExecutors": "5",
				"spark.autotune.trackingId": "a23645b5-23e4-4651-86a2-7e0efb0503cc"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/13d66f54-0a19-4912-b4f3-54d15897368d/resourceGroups/Synapse/providers/Microsoft.Synapse/workspaces/s037-cost-management/bigDataPools/sprkpool33large",
				"name": "sprkpool33large",
				"type": "Spark",
				"endpoint": "https://s037-cost-management.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sprkpool33large",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.3",
				"nodeCount": 3,
				"cores": 16,
				"memory": 112,
				"automaticScaleJobs": true
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from datetime import datetime\r\n",
					"import calendar\r\n",
					"import pyspark.sql.functions as F\r\n",
					"import pyspark.sql.types as T\r\n",
					"import warnings\r\n",
					"from enum import Enum"
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"PROD_OFFER_ID = 'MS-AZR-0017P'"
				],
				"execution_count": 2
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"class AHBStatus(Enum):\r\n",
					"    Enabled = \"Enabled\"\r\n",
					"    NotEnabled = \"Not Enabled\"\r\n",
					"    NotSupported = \"Not Supported\"\r\n",
					"\r\n",
					"class SavingsPlanStatus(Enum):\r\n",
					"    Enabled = \"Enabled\"\r\n",
					"    NotEnabled = \"Not Enabled\"\r\n",
					"    NotBeneficial = \"Not Beneficial\"\r\n",
					"    NotSupported = \"Not Supported\""
				],
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"source": [
					"def get_last_day_prev_month(to_date):\r\n",
					"    current_month = int(to_date[4:6])\r\n",
					"    current_year = int(to_date[:4])\r\n",
					"\r\n",
					"    previous_month = (current_month - 1) if current_month > 1 else 12\r\n",
					"    previous_year = current_year if current_month > 1 else (current_year - 1)\r\n",
					"\r\n",
					"    # Calculating the last day of the month\r\n",
					"    last_day = calendar.monthrange(previous_year, previous_month)[1]\r\n",
					"\r\n",
					"    # Creating a string date for last month\r\n",
					"    return f\"{previous_year}-{str(previous_month).zfill(2)}-{str(last_day).zfill(2)}\""
				],
				"execution_count": 4
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def cost_extend_additional_info(cost_df):\r\n",
					"    # Extend AdditionalInfo Column\r\n",
					"    cost_df = cost_df.withColumn('AdditionalInfo', F.from_json('AdditionalInfo', 'map<string,string>', options={'inferSchema': 'true'}))\r\n",
					"\r\n",
					"    # Creating an ID column\r\n",
					"    cost_df = cost_df.withColumn('id', F.monotonically_increasing_id())\r\n",
					"\r\n",
					"    # Creating a list of columns we want to keep\r\n",
					"    cols_to_keep = [\"UsageType\", \r\n",
					"                    \"ImageType\",\r\n",
					"                    \"ServiceType\",\r\n",
					"                    \"VMName\",\r\n",
					"                    \"VMApplicationName\",\r\n",
					"                    \"VMProperties\",\r\n",
					"                    \"VCPUs\",\r\n",
					"                    \"AHB\",\r\n",
					"                    \"vCores\",\r\n",
					"                    \"RINormalizationRatio\",\r\n",
					"                    \"ConsumedQuantity\",\r\n",
					"                    \"DatabaseName\"]\r\n",
					"\r\n",
					"    for col in cols_to_keep:\r\n",
					"        cost_df = cost_df.withColumn('ai_' + col, F.coalesce(F.col(f'AdditionalInfo.{col}'), F.lit(None)))\r\n",
					"    return cost_df"
				],
				"execution_count": 5
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def preprocess_pricesheet(pricesheet_df):\r\n",
					"    pricesheet_df = pricesheet_df.where(F.col('OfferID') == PROD_OFFER_ID)\r\n",
					"    pricesheet_df = pricesheet_df.withColumn('NormalizedUnit', F.regexp_extract('UnitOfMeasure', r'^(\\d+)', 1).cast('integer'))\r\n",
					"    pricesheet_df = pricesheet_df.withColumn('NormalizedUnitPrice', F.col('UnitPrice') / F.col('NormalizedUnit'))\r\n",
					"    return pricesheet_df"
				],
				"execution_count": 6
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def compute_sp_columns(cost_df, pricesheet_df):\r\n",
					"    # Determine if cost is eligible to SP\r\n",
					"    sp_enabled = (F.col('PricingModel') == 'SavingsPlan') & (F.col('ChargeType') == 'Usage')\r\n",
					"    is_ondemand = (F.col('PricingModel') == 'OnDemand') & (F.col('ChargeType') == 'Usage')\r\n",
					"    is_vm_compute = (F.col('MeterCategory') == 'Virtual Machines') & ~(F.col('MeterSubCategory').contains('Av1'))\r\n",
					"    is_aas_compute = (F.col('MeterCategory') == 'Azure App Service') & (F.col('MeterSubCategory').isin(['Premium v3', 'Isolated v2']))\r\n",
					"    is_af_compute = (F.col('MeterCategory') == 'Functions') & (F.col('MeterSubCategory') == 'Premium')\r\n",
					"    is_aci_compute = (F.col('MeterCategory') == 'Container Instances')\r\n",
					"    is_aca_compute = (F.col('MeterCategory') == 'Azure Container Apps')\r\n",
					"    is_sp_eligible = is_vm_compute | is_aas_compute | is_af_compute | is_aci_compute | is_aca_compute\r\n",
					"\r\n",
					"    cost_df = cost_df.withColumn('SPStatus', \r\n",
					"        F.when(sp_enabled, SavingsPlanStatus.Enabled.value)\r\n",
					"        .when(is_ondemand & is_sp_eligible, SavingsPlanStatus.NotEnabled.value)\r\n",
					"        .otherwise(SavingsPlanStatus.NotSupported.value)\r\n",
					"    )\r\n",
					"\r\n",
					"    # Only use prices for savingsplan for 3 year term\r\n",
					"    pricesheet_df = pricesheet_df.where((F.col('PriceType') == 'SavingsPlan') & (F.col('Term') == 'P3Y'))\r\n",
					"\r\n",
					"    pricesheet_df =  pricesheet_df.withColumn('NormalizedMemoryFactor', \r\n",
					"        F.when(F.col('UnitOfMeasure').contains('TiB'), 1024) # Standard measure in usage file is GiB --> convertion factor between TiB and Gib is 1024\r\n",
					"        .when(F.col('UnitOfMeasure').contains(\"PiB\"), 1048576) # Standard measure in usage file is GiB --> convertion factor between PiB and Gib is 1048576\r\n",
					"        .when(F.col('UnitOfMeasure').contains(\"TB\"), 1000) # Standard measure in usage file is GB --> convertion factor between TB and Gb is 1000\r\n",
					"        .when(F.col('UnitOfMeasure').contains(\"PB\"), 1000000) # Standard measure in usage file is GB --> convertion factor between PB and Gib is 1000000\r\n",
					"        .otherwise(1)\r\n",
					"    )\r\n",
					"    pricesheet_df = pricesheet_df.withColumn('NormalizedP3YSPUnitPrice', F.col('NormalizedUnitPrice') / F.col('NormalizedMemoryFactor'))\r\n",
					"    pricesheet_df = pricesheet_df.select('PartNumber', 'NormalizedP3YSPUnitPrice')\r\n",
					"\r\n",
					"    cost_df = cost_df.join(pricesheet_df, 'PartNumber', 'left')\r\n",
					"\r\n",
					"    # When cost is classified as eligible to SP, but does not av a P3Y Unit Price associated with it - it should not be eligible to SP\r\n",
					"    cost_df = cost_df.withColumn('SPStatus', F.when((F.col('SPStatus') == SavingsPlanStatus.NotEnabled.value) & F.col('NormalizedP3YSPUnitPrice').isNull(), F.lit(SavingsPlanStatus.NotSupported.value)).otherwise(F.col('SPStatus')))\r\n",
					"\r\n",
					"    # Some cost may have a more cost efficient unit price associated to it, than the corresponding 3PY SP unit price - these costs should avoid having SP associat with them\r\n",
					"    cost_df = cost_df.withColumn('SPStatus', F.when((F.col('SPStatus') == SavingsPlanStatus.NotEnabled.value) & (F.col('NormalizedP3YSPUnitPrice') >= F.col('UnitPrice')), F.lit(SavingsPlanStatus.NotBeneficial.value)).otherwise(F.col('SPStatus')))\r\n",
					"\r\n",
					"    return cost_df"
				],
				"execution_count": 7
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def compute_AHB_columns(cost_df, pricesheet_df):\r\n",
					"    ## DETERMINE IF WINDOWS/SQL SERVER IS HUB ENABLED/ELIGIBLE\r\n",
					"\r\n",
					"    # Compute if Windows Server has Azure Hybrid Benefit enabled\r\n",
					"    cost_df = cost_df.withColumn('WindowsAHB', F.when(F.col('ServiceInfo2') == 'Windows Server BYOL', AHBStatus.Enabled.value)\\\r\n",
					"                                                            .when(F.col('MeterSubCategory').contains('Windows'), AHBStatus.NotEnabled.value)\\\r\n",
					"                                                            .otherwise(AHBStatus.NotSupported.value))\r\n",
					"\r\n",
					"    # Compute if SQL Server has Azure Hybrid Benefit enabled\r\n",
					"    is_sql_db = (F.col('ResourceId').like('%Microsoft.Sql/servers%')) & (F.col('MeterCategory').like('SQL%'))\r\n",
					"    is_sql_mi = (F.col('ResourceId').like('%Microsoft.Sql/managedInstances%')) & (F.col('MeterCategory').like('SQL%'))\r\n",
					"    is_sql_vm = (F.col('MeterCategory') == 'Virtual Machines Licenses') & (F.col('MeterSubCategory').like('SQL Server%'))\r\n",
					"    is_sql_arc = (F.col('ResourceId').like('%Microsoft.AzureArcData/sqlServerInstances%')) & (F.col('ai_AHB').isNotNull())\r\n",
					"    is_sql_adf = (F.col('MeterCategory') == 'Azure Data Factory v2') & (F.col('MeterSubCategory').like('SSIS%'))\r\n",
					"\r\n",
					"    is_sql_cost = is_sql_db | is_sql_mi | is_sql_vm | is_sql_arc | is_sql_adf\r\n",
					"\r\n",
					"    NOT_SUPPORTED_AHB_SUBCATEGORIES = [\r\n",
					"        'SQL Server Express Edition',\r\n",
					"        'SQL Server Developer Edition',\r\n",
					"        'SQL Server Web',\r\n",
					"        'SingleDB/Elastic Pool Hyperscale - SQL License',\r\n",
					"        'SQL Server Azure Disaster Recovery Benefit'\r\n",
					"    ]\r\n",
					"\r\n",
					"    NOT_SUPPORTED_PRODUCT_NAMES = [\r\n",
					"        'Azure Arc-enabled SQL Server - Arc-enabled servers - Express edition',\r\n",
					"        'Azure Arc-enabled SQL Server - Arc-enabled servers - Dev edition',\r\n",
					"        'Azure Arc-enabled SQL Server - Arc-enabled servers - Web edition'\r\n",
					"    ]\r\n",
					"\r\n",
					"    is_not_supported = (F.col('MeterSubCategory').isin(NOT_SUPPORTED_AHB_SUBCATEGORIES)) | (F.col('ProductName').isin(NOT_SUPPORTED_PRODUCT_NAMES)) | (F.col('ResourceName').startswith('CVD-'))\r\n",
					"\r\n",
					"    is_vm = F.col('ResourceId').like('%Microsoft.Compute/virtualMachines%')\r\n",
					"    is_vm_ahb = is_vm & (F.col('MeterSubCategory') == 'SQL Server Azure Hybrid Benefit')\r\n",
					"\r\n",
					"    cost_df = cost_df.withColumn('SQLAHB', \r\n",
					"        F.when(is_sql_cost & is_not_supported, AHBStatus.NotSupported.value)\r\n",
					"        .when(is_sql_cost & is_vm_ahb, AHBStatus.Enabled.value)\r\n",
					"        .when(is_sql_cost & is_vm, AHBStatus.NotEnabled.value)\r\n",
					"        .when(is_sql_cost & (F.col('ai_AHB') == True), AHBStatus.Enabled.value)\r\n",
					"        .when(is_sql_cost & (F.col('ai_AHB') == False), AHBStatus.NotEnabled.value)\r\n",
					"        .when(is_sql_adf & F.col('MeterName').like('%AHB%'), AHBStatus.Enabled.value)\r\n",
					"        .when(is_sql_adf & F.col('MeterName').like('%License Included%'), AHBStatus.NotEnabled.value)\r\n",
					"        .otherwise(AHBStatus.NotSupported.value)\r\n",
					"    )\r\n",
					"\r\n",
					"    ## COMPUTE HUB NORMALIZED VCPUS FOR WINDOWS/SQL\r\n",
					"    \r\n",
					"    cost_df = cost_df.withColumn('ai_VCPUs', F.col('ai_VCPUs').cast('int'))\r\n",
					"    cost_df = cost_df.na.fill({'ai_VCPUs' : 0})\r\n",
					"\r\n",
					"    cost_df = cost_df.withColumn('ai_vCores', F.col('ai_vCores').cast('int'))\r\n",
					"    cost_df = cost_df.na.fill({'ai_vCores' : 0})\r\n",
					"\r\n",
					"    is_standard_sql_license = F.col('ProductName').like('%Standard%') | F.col('ProductName').like('%General%') | F.col('ProductName').like('%Std%')\r\n",
					"    is_enterprise_sql_license = F.col('ProductName').like('%Enterprise%') | F.col('ProductName').like('%Critical%') | F.col('ProductName').like('%Ent%')\r\n",
					"\r\n",
					"    # Compute the Windows AHB equivalent VCPUs\r\n",
					"    cost_df = cost_df.withColumn('WindowsAHB_VCPUS', \r\n",
					"        F.when(F.col('ai_VCPUs') == 0, 0)\r\n",
					"        .when(F.col('ai_VCPUs') <= 8, 8)\r\n",
					"        .when(F.col('ai_VCPUs') <= 16, 16)\r\n",
					"        .when(F.col('ai_VCPUs') == 20, 24)\r\n",
					"        .when(F.col('ai_VCPUs') > 20, F.col('ai_VCPUs'))\r\n",
					"        .otherwise(0)\r\n",
					"    )\r\n",
					"\r\n",
					"    # Extract vCore count for ADF SQL resource with this pattern\r\n",
					"    adf_vcore_pattern = r'[A-Za-z](\\d+)'\r\n",
					"    adf_vcores = F.regexp_extract(F.col('MeterName'), adf_vcore_pattern, 1).cast(T.IntegerType())\r\n",
					"\r\n",
					"    # Compute the SQL AHB equivalent VCPUs\r\n",
					"    cost_df = cost_df.withColumn('SQLAHB_VCPUS', \r\n",
					"        F.when(is_sql_vm & (F.col('ai_VCPUs') == 0), 0)\r\n",
					"        .when(is_sql_vm & is_standard_sql_license & (F.col('ai_VCPUs') <= 4), 4)\r\n",
					"        .when(is_sql_vm & is_standard_sql_license & (F.col('ai_VCPUs') > 4), F.col('ai_VCPUs'))\r\n",
					"        .when(is_sql_vm & is_enterprise_sql_license & (F.col('ai_VCPUs') <= 4), 16)\r\n",
					"        .when(is_sql_vm & is_enterprise_sql_license & (F.col('ai_VCPUs') > 4), F.col('ai_VCPUs') * 4)\r\n",
					"        .when((is_sql_mi | is_sql_db | is_sql_arc) & (F.col('ai_vCores') == 0), 0)\r\n",
					"        .when((is_sql_mi | is_sql_db | is_sql_arc) & is_standard_sql_license, F.col('ai_vCores'))\r\n",
					"        .when((is_sql_mi | is_sql_db | is_sql_arc) & is_enterprise_sql_license, F.col('ai_vCores') * 4)\r\n",
					"        .when(is_sql_adf & is_standard_sql_license, adf_vcores)\r\n",
					"        .when(is_sql_adf & is_enterprise_sql_license, adf_vcores * 4)\r\n",
					"        .otherwise(0)\r\n",
					"    )\r\n",
					"\r\n",
					"    ## COMPUTE HUB PAYG LICENSE COST\r\n",
					"\r\n",
					"    is_windows_hub_eligible = (F.col('WindowsAHB') != AHBStatus.NotSupported.value)\r\n",
					"    is_sql_hub_eligible = (F.col('SQLAHB') != AHBStatus.NotSupported.value)\r\n",
					"\r\n",
					"    cost_df = cost_df.withColumn('PricesheetJoinKey', \r\n",
					"        F.when(is_windows_hub_eligible,\r\n",
					"            F.concat(\r\n",
					"                F.lit('Windows Server'),\r\n",
					"                F.when(F.col('MeterSubCategory') == 'Windows Server Burst', ' Burst - ').otherwise(' - '), \r\n",
					"                F.col('ai_VCPUs'), \r\n",
					"                F.lit(' vCPU VM License')\r\n",
					"            )\r\n",
					"        )\r\n",
					"        .when(is_sql_hub_eligible & is_sql_mi & is_standard_sql_license, 'SQL Managed Instance General Purpose - SQL License - vCore')\r\n",
					"        .when(is_sql_hub_eligible & is_sql_mi & is_enterprise_sql_license, 'SQL Managed Instance Business Critical - SQL License - vCore')\r\n",
					"        .when(is_sql_hub_eligible & is_sql_db & is_standard_sql_license, 'SQL Database Single/Elastic Pool General Purpose - SQL License - vCore')\r\n",
					"        .when(is_sql_hub_eligible & is_sql_db & is_enterprise_sql_license, 'SQL Database Single/Elastic Pool Business Critical - SQL License - vCore')\r\n",
					"        .when(is_sql_hub_eligible & is_sql_vm & is_standard_sql_license & (F.col('ai_VCPUs') < 5), 'SQL Server Standard - 1-4 vCPU VM License')\r\n",
					"        .when(is_sql_hub_eligible & is_sql_vm & is_enterprise_sql_license & (F.col('ai_VCPUs') < 5), 'SQL Server Enterprise - 1-4 vCPU VM License')\r\n",
					"        .when(is_sql_hub_eligible & is_sql_vm & is_standard_sql_license & (F.col('ai_VCPUs') >= 5), F.concat(F.lit('SQL Server Standard - '), F.col('ai_VCPUs'), F.lit(' vCPU VM License')))\r\n",
					"        .when(is_sql_hub_eligible & is_sql_vm & is_enterprise_sql_license & (F.col('ai_VCPUs') >= 5), F.concat(F.lit('SQL Server Enterprise - '), F.col('ai_VCPUs'), F.lit(' vCPU VM License')))\r\n",
					"        .when(is_sql_hub_eligible & is_sql_adf & is_standard_sql_license, F.concat(F.lit('SSIS '), F.split('MeterName', ' ').getItem(0), F.lit(' '), F.split('MeterName', ' ').getItem(1), F.lit(' - Standard')))\r\n",
					"        .when(is_sql_hub_eligible & is_sql_adf & is_enterprise_sql_license, F.concat(F.lit('SSIS '), F.split('MeterName', ' ').getItem(0), F.lit(' '), F.split('MeterName', ' ').getItem(1), F.lit(' - Enterprise')))\r\n",
					"        .when(is_sql_hub_eligible & is_sql_arc & is_standard_sql_license, 'Azure Arc-enabled SQL Server - Arc-enabled servers - Std edition - License only')\r\n",
					"        .when(is_sql_hub_eligible & is_sql_arc & is_enterprise_sql_license, 'Azure Arc-enabled SQL Server - Arc-enabled servers - Ent edition - License only')\r\n",
					"        .otherwise(None)\r\n",
					"    )\r\n",
					"\r\n",
					"    # Compute license priceses for ADF SSIS SQL compute\r\n",
					"    adf_pricesheet = pricesheet_df.where(is_sql_adf)\r\n",
					"\r\n",
					"    pricesheet_df = pricesheet_df \\\r\n",
					"        .select('Product', 'NormalizedUnitPrice') \\\r\n",
					"        .withColumnRenamed('Product', 'PricesheetJoinKey') \\\r\n",
					"        .withColumnRenamed('NormalizedUnitPrice', 'LicensePayGUnitPrice')\r\n",
					"\r\n",
					"    # Only process if adf related rows exists -> if not the pivoting will fail\r\n",
					"    if adf_pricesheet.count() > 0:\r\n",
					"        adf_pricesheet = adf_pricesheet.withColumn('LicenseType', F.split('MeterSubCategory', ' ').getItem(1))\r\n",
					"        adf_pricesheet = adf_pricesheet.withColumn('ComputeResource', F.concat(F.split('MeterName', ' ').getItem(0), F.lit(' '), F.split('MeterName', ' ').getItem(1)))\r\n",
					"        adf_pricesheet = adf_pricesheet.withColumn('PricesheetJoinKey', F.concat(F.lit('SSIS '), F.col('ComputeResource'), F.lit(' - '), F.col('LicenseType')))\r\n",
					"\r\n",
					"        # Each ADF pricesheet entry has an AHB and a PayG counter-part, use pivot to get the corresponding unit prices into a single pricesheet entry\r\n",
					"        adf_pricesheet = adf_pricesheet.withColumn('AHB', F.when(F.col('MeterType').like('%AHB%'), 'AHBUnitPrice').otherwise('PayGUnitPrice'))\r\n",
					"        adf_pricesheet = adf_pricesheet.groupBy('PricesheetJoinKey').pivot('AHB').agg(F.first('NormalizedUnitPrice'))\r\n",
					"        adf_pricesheet = adf_pricesheet.withColumn('LicensePayGUnitPrice', F.col('PayGUnitPrice') - F.col('AHBUnitPrice'))\r\n",
					"        adf_pricesheet = adf_pricesheet.select('PricesheetJoinKey', 'LicensePayGUnitPrice')\r\n",
					"\r\n",
					"        # Add ADF SSIS License costs to pricesheet\r\n",
					"        pricesheet_df = pricesheet_df.union(adf_pricesheet)\r\n",
					"\r\n",
					"    cost_df = cost_df.join(pricesheet_df, 'PricesheetJoinKey', 'left').drop('PricesheetJoinKey')\r\n",
					"\r\n",
					"    # DB/MI Instances have a PayG Licence unit price per vCore - multiply by vCores to get PayG License cost for entire resource\r\n",
					"    cost_df = cost_df.withColumn('LicensePayGUnitPrice', F.when(is_sql_db | is_sql_mi, F.col('LicensePayGUnitPrice') * F.col('ai_vCores')).otherwise(F.col('LicensePayGUnitPrice')))\r\n",
					"\r\n",
					"    return cost_df"
				],
				"execution_count": 8
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def cost_cast_column_types(cost_df):\r\n",
					"    cost_df = cost_df.withColumn('UnitPrice', F.col('UnitPrice').cast(T.DoubleType()))\\\r\n",
					"                     .withColumn('PayGPrice', F.col('PayGPrice').cast(T.DoubleType()))\\\r\n",
					"                     .withColumn('Quantity', F.col('Quantity').cast(T.DoubleType()))\\\r\n",
					"                     .withColumn('EffectivePrice', F.col('EffectivePrice').cast(T.DoubleType()))\\\r\n",
					"                     .withColumn('CostInBillingCurrency', F.col('CostInBillingCurrency').cast(T.DoubleType()))\\\r\n",
					"                     .withColumn('Date', F.to_date(F.col('Date'), 'MM/dd/yyyy'))\\\r\n",
					"                     .withColumn('BillingPeriodStartDate', F.to_date(F.col('BillingPeriodStartDate'), 'MM/dd/yyyy'))\\\r\n",
					"                     .withColumn('BillingPeriodEndDate', F.to_date(F.col('BillingPeriodEndDate'), 'MM/dd/yyyy'))\r\n",
					"\r\n",
					"    return cost_df"
				],
				"execution_count": 9
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def expand_cost_tags(cost_df):\r\n",
					"    \r\n",
					"    # Storing the Tags column in a new column, and cleaning it up to fit with CostAllocationType\r\n",
					"    cost_df = cost_df.withColumn('CostAllocationType', F.regexp_extract(F.col('Tags'), '(?i)costallocationtype\": \"(.*)\"', 0))\r\n",
					"    cost_df = cost_df.withColumn('CostAllocationType', F.regexp_replace(F.col('CostAllocationType'), '(?i)costallocationtype\": \"', \"\"))\r\n",
					"    cost_df = cost_df.withColumn('CostAllocationType', F.split(F.col('CostAllocationType'),'\"', 0).getItem(0))\r\n",
					"    cost_df = cost_df.withColumn('CostAllocationType', F.when(F.col('CostAllocationType') == \"\", None).otherwise(F.col('CostAllocationType')))\r\n",
					"    cost_df = cost_df.withColumn('CostAllocationTypeTag', F.col('CostAllocationType'))\r\n",
					"\r\n",
					"    # Storing the Tags column in a new column, and cleaning it up to fit with CostAllocationCode\r\n",
					"    cost_df = cost_df.withColumn('CostAllocationCode', F.regexp_extract(F.col('Tags'), '(?i)costallocationcode\": \"(.*)\"', 0))\r\n",
					"    cost_df = cost_df.withColumn('CostAllocationCode', F.regexp_replace(F.col('CostAllocationCode'), '(?i)costallocationcode\": \"', \"\"))\r\n",
					"    cost_df = cost_df.withColumn('CostAllocationCode', F.split(F.col('CostAllocationCode'),'\"', 0).getItem(0))\r\n",
					"    cost_df = cost_df.withColumn('CostAllocationCode', F.when(F.col('CostAllocationCode') == \"\", None).otherwise(F.col('CostAllocationCode')))\r\n",
					"    cost_df = cost_df.withColumn('CostAllocationCodeTag', F.col('CostAllocationCode'))\r\n",
					"    \r\n",
					"    print(\"Cost Tags expansion complete\")\r\n",
					"\r\n",
					"    return cost_df"
				],
				"execution_count": 10
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def replace_empty_cost_fields_with_subscription_details(cost_df, application_df):\r\n",
					"    print(\"Creating ActiveWBS column, copying over CostAllocationCode, replacing 'TOBESPECIFIED' and empty values then filling gaps with SubscriptionWBS...\")\r\n",
					"\r\n",
					"    # Apply Upper-case for all CostAllocationTypes and Codes\r\n",
					"    cost_df = cost_df.withColumn('CostAllocationType', F.upper(F.col('CostAllocationType')))\r\n",
					"    cost_df = cost_df.withColumn('CostAllocationCode', F.trim(F.upper(F.col('CostAllocationCode'))))\r\n",
					"\r\n",
					"    # When the tag does not contain CostAllocationCode or CostAllocationType, then we fill/replace the value in ActiveWBSReason\r\n",
					"    invalidCostAllocationMask = F.col('CostAllocationCode').isNull() | F.col('CostAllocationType').isNull()\r\n",
					"    cost_df = cost_df.withColumn('ActiveWBSReason', F.when(invalidCostAllocationMask, F.lit('CostAllocationType or CostAllocationCode not present in Tags')))\r\n",
					"\r\n",
					"    # When either value in mask appears in AcitveWBS, add invalid reason in new column\r\n",
					"    validCostAllocationType = ['WBS', 'APPID', 'CI']\r\n",
					"    cost_df = cost_df.withColumn('ActiveWBSReason', F.when(~F.col('CostAllocationType').isin(validCostAllocationType), F.lit('Invalid CostAllocationType: not APPID, CI or WBS')).otherwise(F.col('ActiveWBSReason')))\r\n",
					"\r\n",
					"    # When the values in the columns below match the mask and the cost type is WBS, then:\r\n",
					"    # regex pattern states that the string should start with a case insensitive letter, followed by a dot, followed by either letters, numbers or dots\r\n",
					"    pattern = r'^[a-zA-Z]\\.[a-zA-Z0-9.]+$'\r\n",
					"    rmask = F.col('CostAllocationCode').rlike(pattern)\r\n",
					"    cost_wbs = (F.col('CostAllocationType') == 'WBS')\r\n",
					"\r\n",
					"    # Applying valid WBS' as Active WBS'\r\n",
					"    # 1. Where the CostAllocationCode follows the regex and the CostAllocationType is WBS, we apply the CostAllocationCode\r\n",
					"    cost_df = cost_df.withColumn('ActiveWBS', F.when(cost_wbs & rmask, F.col('CostAllocationCode')))\r\n",
					"    # 2. Where the CostAllocationCode doesn't follow the regex and the CostAllocationType is WBS, we set the ActiveWBSReason to be \"Invalid CostAllocationCode WBS\"\r\n",
					"    cost_df = cost_df.withColumn('ActiveWBSReason', F.when(cost_wbs & ~rmask, F.lit('Invalid CostAllocationCode WBS')).otherwise(F.col('ActiveWBSReason')))\r\n",
					"    # 3. Where the CostAllocationCode doesn't follow the regex and the CostAllocationType is WBS, the CostAllocationType is changed to \"SubscriptionWBS\"\r\n",
					"    cost_df = cost_df.withColumn('CostAllocationType', F.when(cost_wbs & ~rmask, F.lit('SubscriptionWBS')).otherwise(F.col('CostAllocationType')))\r\n",
					"\r\n",
					"    # Applying valid AppIDs as Active WBS'\r\n",
					"    # If the CostAllocationCode is empty, we fill/replace the column ActiveWBS with Operational WBS in the application_df\r\n",
					"    map_app = application_df.withColumn('AppID', F.col('AppID').cast(T.StringType())).select('AppID', 'OperationalWBS')\r\n",
					"    joined_df = cost_df.join(map_app, (cost_df.CostAllocationType == 'APPID') & (cost_df.CostAllocationCode == map_app.AppID), how='left')\r\n",
					"    cost_df = joined_df.withColumn('ActiveWBS', F.when(F.col('ActiveWBS').isNull(), F.col('OperationalWBS')).otherwise(F.col('ActiveWBS')))\r\n",
					"    cost_df = cost_df.drop('OperationalWBS')\r\n",
					"\r\n",
					"    # Applying valid CIs as Active WBS'\r\n",
					"    # Same here as above, but we merge the dataframes on ApplicationNames rather than AppID\r\n",
					"    map_app = application_df.select('ApplicationName', 'OperationalWBS')\r\n",
					"    # Apply join with case insensitivity\r\n",
					"    map_app = map_app.withColumn('ApplicationName_upper',F.upper(F.col('ApplicationName')))\r\n",
					"    joined_df = cost_df.join(map_app, (cost_df.CostAllocationType == 'CI') & (cost_df.CostAllocationCode == map_app.ApplicationName_upper), how='left').drop('ApplicationName_upper')\r\n",
					"    cost_df = joined_df.withColumn('ActiveWBS', F.when(F.col('ActiveWBS').isNull(), F.col('OperationalWBS')).otherwise(F.col('ActiveWBS')))\r\n",
					"    \r\n",
					"    # Alternative 1 remove \"AppID\" \r\n",
					"    cost_df = cost_df.drop('ApplicationName', 'OperationalWBS')\r\n",
					"\r\n",
					"    # When ActiveWBS value is string 'TOBESPECIFIED', we replace the value with None. # Why this ActiveWBS have TOBSPECIFIED value? \r\n",
					"    cost_df = cost_df.withColumn('ActiveWBS', F.when(F.upper(F.col('ActiveWBS')) == 'TOBESPECIFIED', F.lit(None)).otherwise(F.col('ActiveWBS')))\r\n",
					"\r\n",
					"    # When Subscriptions are not attached to the costs (unassigned), we fill the values with Unassigned and state the ActiveWBSReason.\r\n",
					"    cost_df = cost_df.withColumn('CostAllocationType', F.when(F.col('SubscriptionName') == 'Unassigned', F.lit('Unassigned')).otherwise(F.col('CostAllocationType')))\r\n",
					"    cost_df = cost_df.withColumn('ActiveWBS', F.when(F.col('SubscriptionName') == 'Unassigned', F.lit('Unassigned')).otherwise(F.col('ActiveWBS')))\r\n",
					"    cost_df = cost_df.withColumn('ActiveWBSReason', F.when(F.col('SubscriptionName') == 'Unassigned', F.lit('Unassigned Subscription, possibly unused RI/SP')).otherwise(F.col('ActiveWBSReason')))\r\n",
					"\r\n",
					"    # Now that we have filled in most places in ActiveWBS, if the rest of ActiveWBS is Null, then we apply the CostCenter WBS\r\n",
					"    # When CostAllocationType is null, we fill it with the value from SubscriptionWBS\r\n",
					"    cost_df = cost_df.withColumn('ActiveWBSReason', F.when(F.col('ActiveWBS').isNull() & (F.col('CostAllocationType') == 'APPID'), F.lit('AppID CostAllocationCode Invalid or Missing')).otherwise(F.col('ActiveWBSReason')))\r\n",
					"    cost_df = cost_df.withColumn('ActiveWBSReason', F.when(F.col('ActiveWBS').isNull() & (F.col('CostAllocationType') == 'CI'), F.lit('CI CostAllocationCode Invalid or Missing')).otherwise(F.col('ActiveWBSReason')))\r\n",
					"    cost_df = cost_df.withColumn('CostAllocationType', F.when(F.col('ActiveWBS').isNull(), F.lit('SubscriptionWBS')).otherwise(F.col('CostAllocationType')))\r\n",
					"    cost_df = cost_df.withColumn('ActiveWBS', F.when(F.col('ActiveWBS').isNull(), F.col('CostCenter')).otherwise(F.col('ActiveWBS'))) # Cost Center is identical to SubscriptionWBS. So we can remove subscription.json.\r\n",
					"    cost_df = cost_df.withColumn('CostAllocationType', F.when(~F.col('CostAllocationType').isin(validCostAllocationType), F.lit('SubscriptionWBS')).otherwise(F.col('CostAllocationType')))\r\n",
					"    cost_df = cost_df.withColumn('CostAllocationType', F.when(F.col('CostAllocationType').isNull(), F.lit('SubscriptionWBS')).otherwise(F.col('CostAllocationType'))) #  Can be removed.\r\n",
					"\r\n",
					"    cost_df = cost_df.withColumn('ActiveWBSReason', F.when(F.col('ActiveWBSReason').isNull() & (F.col('CostAllocationType') == 'SubscriptionWBS'), F.lit('No valid AppID, WBS or CI')).otherwise(F.col('ActiveWBSReason')))\r\n",
					"    \r\n",
					"\r\n",
					"    # When CostAllocationType is a specific string, we fill/replace the value in ActiveWBSReason \r\n",
					"    cost_df = cost_df.withColumn('ActiveWBSReason', F.when(F.col('CostAllocationType') == 'CI', F.lit('CI WBS Lookup from SNOW')).otherwise(F.col('ActiveWBSReason')))\r\n",
					"    cost_df = cost_df.withColumn('ActiveWBSReason', F.when(F.col('CostAllocationType') == 'APPID', F.lit('AppID WBS Lookup from SNOW')).otherwise(F.col('ActiveWBSReason')))\r\n",
					"    cost_df = cost_df.withColumn('ActiveWBSReason', F.when(F.col('CostAllocationType') == 'WBS', F.lit('WBS Cost Tag used')).otherwise(F.col('ActiveWBSReason')))\r\n",
					"\r\n",
					"    cost_df = cost_df.withColumn('ActiveWBS', F.upper(F.col('ActiveWBS')))\r\n",
					"\r\n",
					"    # For cases that where CostAllocationCode is empty, we will use AppID from SerivceNow and Application from Subscription.json to replace.\r\n",
					"    mask3 = (F.col('CostAllocationType').isin(['APPID']) & F.col('CostAllocationCode').isNull())\r\n",
					"    mask4 = (F.col('CostAllocationType').isin(['CI']) & F.col('CostAllocationCode').isNull())\r\n",
					"    cost_df = cost_df.withColumn('CostAllocationCode', F.when(mask3, F.col('AppID')) \\\r\n",
					"                                                       .when(mask4, F.col('SubscriptionServiceNow-App')) \\\r\n",
					"                                                       .otherwise(F.col('CostAllocationCode'))).drop('AppID')\r\n",
					"\r\n",
					"    return cost_df"
				],
				"execution_count": 11
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def get_application_names(cost_df, application_df):\r\n",
					"\r\n",
					"    # Masks for CI and AppID\r\n",
					"    ci_mask = F.col('CostAllocationType') == 'CI'\r\n",
					"    appid_mask = F.col('CostAllocationType') == 'APPID'\r\n",
					"\r\n",
					"    # When AppID is present, we use the application name from the Service-Now Application list\r\n",
					"    # First convert AppID to a string, then select the desired columns\r\n",
					"    map_app = application_df.withColumn('AppID', F.col('AppID').cast(T.StringType())).select('AppID', 'ApplicationName')\r\n",
					"\r\n",
					"    # Apply case insensitivity merge by creating upper case columns\r\n",
					"    cost_df = cost_df.withColumn('CostAllocationCode_upper',F.upper(F.col('CostAllocationCode')))\r\n",
					"    map_app = map_app.withColumn('ApplicationName_upper',F.upper(F.col('ApplicationName')))\r\n",
					"\r\n",
					"    # Merge CostAllocationCode on APPID\r\n",
					"    cost_df = cost_df.join(map_app, cost_df.CostAllocationCode_upper == map_app.AppID, how='left')\r\n",
					"\r\n",
					"    # Make copy of service now app list for second merge\r\n",
					"    map_app_copy = map_app.alias('map_app_copy').withColumnRenamed('AppID', 'NewAppID').withColumnRenamed('ApplicationName_upper', 'NewApplicationName_upper').withColumnRenamed('ApplicationName', 'NewApplicationName')\r\n",
					"\r\n",
					"    # Merge CostAllicationCode on ApplicationName copy\r\n",
					"    cost_df = cost_df.join(map_app_copy, cost_df.CostAllocationCode_upper == map_app_copy.NewApplicationName_upper, how='left')\r\n",
					"\r\n",
					"    # Populate original AppId and ApplicationName columns from the copied columns\r\n",
					"    cost_df = cost_df.withColumn('AppID', F.when(F.col('AppID').isNull(), F.col('NewAppID')).otherwise(F.col('AppID')))\r\n",
					"    cost_df = cost_df.withColumn('ApplicationName', F.when(F.col('ApplicationName').isNull(), F.col('NewApplicationName')).otherwise(F.col('ApplicationName')))\r\n",
					"\r\n",
					"    cost_df = cost_df.drop('CostAllocationCode_upper', 'ApplicationName_upper', 'NewAppID', 'NewApplicationName_upper', 'NewApplicationName')\r\n",
					"\r\n",
					"    # Create Application_Name column based on Application from ServiceNow to start with.\r\n",
					"    cost_df = cost_df.withColumn('Application_Name',F.col('ApplicationName'))\r\n",
					"\r\n",
					"    # Resolve CostAllocationCode and CostAllocationType typo by replacing Application_name with SubscriptionServiceNow-App value \r\n",
					"    cost_df = cost_df.withColumn('Application_Name',F.when((F.col('CostAllocationType') == 'APPID') & F.col('CostAllocationCode').cast('int').isNull(),F.col('SubscriptionServiceNow-App'))\\\r\n",
					"                                                    .when((F.col('CostAllocationType') == 'CI') & F.col('CostAllocationCode').cast('int').isNotNull(),F.col('SubscriptionServiceNow-App')).otherwise(F.col('Application_Name')))\r\n",
					"\r\n",
					"    cost_df = cost_df.withColumn('Application_Name',F.when(((F.col('CostAllocationType') == \"SubscriptionWBS\") | (F.col('CostAllocationType') == \"WBS\"))&(F.col('Application_Name').isNull()),F.col('SubscriptionServiceNow-App'))\\\r\n",
					"                                                     .otherwise(F.col('Application_Name')))\r\n",
					"\r\n",
					"    cost_df = cost_df.withColumn('Application_Name_upper',F.upper(F.col('Application_Name')))\r\n",
					"    map_app = map_app.withColumn('ServiceNowApplicationName_upper',F.upper(F.col('ApplicationName')))\r\n",
					"    map_app = map_app.withColumn('ServiceNowAppID',F.col('AppID')).drop('AppID')\r\n",
					"\r\n",
					"    # Lookup application in ServiceNow. Those applications that can be found will be merged.\r\n",
					"    cost_df = cost_df.join(map_app,cost_df.Application_Name_upper==map_app.ServiceNowApplicationName_upper,how='left')\r\n",
					"\r\n",
					"    # Fill empty AppID with AppID from ServiceNow\r\n",
					"    cost_df = cost_df.withColumn('AppID',F.when(F.col('AppID').isNull(),F.col('ServiceNowAppID'))\\\r\n",
					"                                          .otherwise(F.col('AppID'))) \r\n",
					"\r\n",
					"    # Remove unused Columns\r\n",
					"    cost_df = cost_df.drop('Application_Name_upper','ApplicationName','ServiceNowAppID','ServiceNowApplicationName_upper','ApplicationName_upper')\r\n",
					"\r\n",
					"\r\n",
					"    # Application Name will be \"Unknown\" when SubscriptionServiceNow-App is equal to Application_name as well as AppID is empty.\r\n",
					"    # This indicates that application from subscription.json file can not be found in ServiceNow. One of Application example is DATAHUB - MARKETING AND SUPPLY, not found in ServiceNow.\r\n",
					"    # cost_df = cost_df.withColumn('Application_Name', F.when((F.upper(F.col('SubscriptionServiceNow-App'))==F.upper(F.col('Application_Name'))) & (F.col('AppID').isNull()),F.lit('Uknown'))\\\r\n",
					"    #                                                 .otherwise(F.col('Application_Name')))\r\n",
					"\r\n",
					"    # If Subscription Application is empty or null - set application name to 'Unknown' and AppId to null\r\n",
					"    cost_df = cost_df.withColumn('Application_Name', \r\n",
					"        F.when((F.col('Application_Name').isNull()) | (F.col('Application_Name') == ''), F.lit('Unknown')).otherwise(F.col('Application_Name'))\r\n",
					"    )\r\n",
					"\r\n",
					"    # Setup dummy application reference for Danske Commodities related cost\r\n",
					"    cost_df = cost_df.withColumn('Application_Name', \r\n",
					"        F.when((F.upper(F.col('SubscriptionName')).contains('DANSKE')) & (F.col('Application_Name') == 'Unknown'), 'Danske Commodities')\r\n",
					"        .otherwise(F.col('Application_Name'))\r\n",
					"    )\r\n",
					"\r\n",
					"    return cost_df"
				],
				"execution_count": 12
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def add_azure_service_information(cost_df, service_df):\r\n",
					"    # Remove duplicate rows by groupBy+count\r\n",
					"    service_df = service_df.withColumn('service_ResourceType', F.lower('ResourceType'))\r\n",
					"    service_df = service_df.groupBy('service_ResourceType','ServiceName','ServiceCategory', 'ServiceModel').count().drop('count')\r\n",
					"\r\n",
					"    # Count number of distinct resourcetypes in dataset\r\n",
					"    count_df = service_df.groupBy('service_ResourceType').count()\r\n",
					"\r\n",
					"    # Separate services with unique resource types (unambiguous in terms of service type) - i.e where the count of resource types is 1\r\n",
					"    unambig_df = count_df.filter(count_df['count'] == 1).join(service_df, 'service_ResourceType').drop('count')\r\n",
					"\r\n",
					"    # Separate services with ambiguity in terms of service types - i.e where the count of resource types is greater than 0\r\n",
					"    ambig_df = count_df.filter(count_df['count'] > 1).join(service_df, 'service_ResourceType').drop('count')\r\n",
					"\r\n",
					"    # Add prefix to service datasets for joining purposes\r\n",
					"    unambig_prefix = 'unambig_'\r\n",
					"    for col in unambig_df.columns:\r\n",
					"        unambig_df = unambig_df.withColumnRenamed(col, unambig_prefix + col)\r\n",
					"\r\n",
					"    unambig_prefix = 'ambig_'\r\n",
					"    for col in ambig_df.columns:\r\n",
					"        ambig_df = ambig_df.withColumnRenamed(col, unambig_prefix + col)\r\n",
					"\r\n",
					"    # Extract resource type from resource id\r\n",
					"    cost_df = cost_df.withColumn('temp_resource_id', F.lower(F.col('ResourceId')))\r\n",
					"    cost_df = cost_df.withColumn('ResourceType', F.regexp_extract('temp_resource_id', '/providers/([^/]+/[^/]+)', 1)).drop('temp_resource_id')\r\n",
					"\r\n",
					"    # Join cost resource types on unambiguous resource types\r\n",
					"    cost_df = cost_df.join(unambig_df, cost_df.ResourceType == unambig_df.unambig_service_ResourceType, how='left').drop('unambig_service_ResourceType')\r\n",
					"\r\n",
					"    # Join cost resource types and meter category on ambiguous resource types and service name\r\n",
					"    cost_df = cost_df.join(ambig_df, (cost_df.ResourceType == ambig_df.ambig_service_ResourceType) & (cost_df.MeterCategory == ambig_df.ambig_ServiceName), how='left').drop('ambig_service_ResourceType')\r\n",
					"\r\n",
					"    # Merge joined service columns and drop remaining columns from service datasets \r\n",
					"    cost_df = cost_df.withColumn('ServiceModel', F.when(F.col('unambig_ServiceModel').isNotNull(), F.col('unambig_ServiceModel')).otherwise(F.col('ambig_ServiceModel')))\r\n",
					"    cost_df = cost_df.withColumn('ServiceName', F.when(F.col('unambig_ServiceName').isNotNull(), F.col('unambig_ServiceName')).otherwise(F.col('ambig_ServiceName')))\r\n",
					"    cost_df = cost_df.withColumn('ServiceCategory', F.when(F.col('unambig_ServiceCategory').isNotNull(), F.col('unambig_ServiceCategory')).otherwise(F.col('ambig_ServiceCategory')))\r\n",
					"    cost_df = cost_df.drop('ambig_ServiceModel', 'ambig_ServiceName', 'ambig_ServiceCategory', 'unambig_ServiceModel', 'unambig_ServiceName', 'unambig_ServiceCategory')\r\n",
					"\r\n",
					"    # Join cost resource types and meter sub category on ambiguous resource types and service name\r\n",
					"    cost_df = cost_df.join(ambig_df, (cost_df.ResourceType == ambig_df.ambig_service_ResourceType) & (cost_df.MeterSubCategory == ambig_df.ambig_ServiceName), how='left').drop('ambig_service_ResourceType')\r\n",
					"\r\n",
					"    # Merge joined columns with previously merged service columns\r\n",
					"    cost_df = cost_df.withColumn('ServiceModel', F.when(F.col('ServiceModel').isNotNull(), F.col('ServiceModel')).otherwise(F.col('ambig_ServiceModel')))\r\n",
					"    cost_df = cost_df.withColumn('ServiceName', F.when(F.col('ServiceName').isNotNull(), F.col('ServiceName')).otherwise(F.col('ambig_ServiceName')))\r\n",
					"    cost_df = cost_df.withColumn('ServiceCategory', F.when(F.col('ServiceCategory').isNotNull(), F.col('ServiceCategory')).otherwise(F.col('ambig_ServiceCategory')))\r\n",
					"    cost_df = cost_df.drop('ambig_ServiceModel', 'ambig_ServiceName', 'ambig_ServiceCategory')\r\n",
					"\r\n",
					"    return cost_df"
				],
				"execution_count": 13
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def transform_cost_data(cost_df):\r\n",
					"\r\n",
					"    warnings.simplefilter(action='ignore', category=FutureWarning)\r\n",
					"    cost_df = cost_extend_additional_info(cost_df)\r\n",
					"    cost_df = cost_cast_column_types(cost_df)\r\n",
					"    cost_df = expand_cost_tags(cost_df)\r\n",
					"    cost_df = cost_df.withColumn(\"ResourceLocation\", F.lower(F.trim(F.regexp_replace(F.col('ResourceLocation'), \"\\s+\", \"\"))))\r\n",
					"    \r\n",
					"    return cost_df"
				],
				"execution_count": 14
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def compute_hub_and_sp(cost_df, pricesheet_df):\r\n",
					"    pricesheet_df = preprocess_pricesheet(pricesheet_df)\r\n",
					"    cost_df = compute_sp_columns(cost_df, pricesheet_df)\r\n",
					"    cost_df = compute_AHB_columns(cost_df, pricesheet_df)\r\n",
					"    return cost_df"
				],
				"execution_count": 15
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def combine_subscriptions_and_applications(cost_df, subscription_df, application_df):\r\n",
					"    \r\n",
					"    cost_df = cost_df.join(subscription_df, cost_df.SubscriptionId == subscription_df.SubId, how='left')\r\n",
					"    cost_df = cost_df.drop('SubId')\r\n",
					"\r\n",
					"    cost_df = replace_empty_cost_fields_with_subscription_details(cost_df, application_df)\r\n",
					"    print('WBS population complete. Populating application names')\r\n",
					"    cost_df = get_application_names(cost_df, application_df)    \r\n",
					"    print('App-name population complete')\r\n",
					"\r\n",
					"    return cost_df"
				],
				"execution_count": 16
			}
		]
	}
}