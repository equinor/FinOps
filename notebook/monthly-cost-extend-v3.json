{
	"name": "monthly-cost-extend-v3",
	"properties": {
		"folder": {
			"name": "NotebookInProduction/Cost Extension"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "sprkpool33large",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "112g",
			"driverCores": 16,
			"executorMemory": "112g",
			"executorCores": 16,
			"numExecutors": 1,
			"runAsWorkspaceSystemIdentity": false,
			"conf": {
				"spark.dynamicAllocation.enabled": "true",
				"spark.dynamicAllocation.minExecutors": "1",
				"spark.dynamicAllocation.maxExecutors": "4",
				"spark.autotune.trackingId": "b3efbf06-1436-4136-b11a-d714c5717418"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/13d66f54-0a19-4912-b4f3-54d15897368d/resourceGroups/Synapse/providers/Microsoft.Synapse/workspaces/s037-cost-management/bigDataPools/sprkpool33large",
				"name": "sprkpool33large",
				"type": "Spark",
				"endpoint": "https://s037-cost-management.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sprkpool33large",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.3",
				"nodeCount": 3,
				"cores": 16,
				"memory": 112,
				"automaticScaleJobs": true
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Initialize script"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"tags": [
						"parameters"
					]
				},
				"source": [
					"toDate = '20240131'\n",
					"fromDate = '20240101'\n",
					"container = 'usage'\n",
					"storageAccount = 's037costmgmt'\n",
					"reportType = 'AmortizedCost'"
				],
				"execution_count": 112
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"import pandas as pd\n",
					"import pyspark.pandas as ps\n",
					"import json\n",
					"import numpy as np\n",
					"from datetime import datetime\n",
					"import calendar\n",
					"import warnings\n",
					"\n",
					"import pyspark.sql.functions as F\n",
					"import pyspark.sql.types as T"
				],
				"execution_count": 100
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Load utility functions"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"%run /cost-extend-utilities"
				],
				"execution_count": 101
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def load_and_process_solum_subscriptions(subscription_path):\r\n",
					"\r\n",
					"    subscription_df = spark.read.json(subscription_path)\r\n",
					"    subscription_df = subscription_df.withColumnRenamed('id', 'SubId')\r\n",
					"    subscription_df = subscription_df.withColumn('id', F.monotonically_increasing_id())\r\n",
					"\r\n",
					"    try:\r\n",
					"        subscription_df = subscription_df.withColumn('tags', F.from_json(F.col('tags')))\r\n",
					"    except:\r\n",
					"        print('Already a json file')\r\n",
					"\r\n",
					"    # Expanding the tags list into separate columns\r\n",
					"    subscription_df = subscription_df.withColumn('SubscriptionWBS', F.col('tags.WBS'))\r\n",
					"    subscription_df = subscription_df.withColumn('SubscriptionServiceNow-App', F.col('tags.ServiceNow-App'))\r\n",
					"    subscription_df = subscription_df.drop('tags')\r\n",
					"\r\n",
					"    # Dropping unnecessary columns and setting the schema\r\n",
					"    columns_to_keep = ['SubId', 'SubscriptionWBS', 'SubscriptionServiceNow-App']\r\n",
					"    subscription_df = subscription_df.select(columns_to_keep)\r\n",
					"\r\n",
					"    return subscription_df\r\n",
					"\r\n",
					"def load_and_process_servicenow_subscriptions(subscription_path):\r\n",
					"    subscription_df = spark.read.format('parquet').load(subscription_path)\r\n",
					"    subscription_df = subscription_df.select('SubscriptionId', 'OperationalWBS', 'Application')\r\n",
					"    subscription_df = subscription_df.withColumnRenamed('SubscriptionId', 'SubId')\r\n",
					"    subscription_df = subscription_df.withColumnRenamed('OperationalWBS', 'SubscriptionWBS')\r\n",
					"    subscription_df = subscription_df.withColumnRenamed('Application', 'SubscriptionServiceNow-App')\r\n",
					"    return subscription_df\r\n",
					"\r\n",
					"def load_and_process_applications(application_path):\r\n",
					"    application_df = spark.read.format('parquet').load(application_path)\r\n",
					"    application_df = application_df.withColumn('AppID', F.col('AppID').cast(\"int\"))\r\n",
					"    return application_df"
				],
				"execution_count": 102
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def write_output_file(cost_df, destinationFilename):\n",
					"\n",
					"    cost_df = cost_df.drop('id', 'AdditionalInfo') \n",
					"    print('start to write to container')\n",
					"    cost_df.write.format('parquet').mode('overwrite').option('path', destinationFilename).save()\n",
					"    print('File write complete!')"
				],
				"execution_count": 103
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Execute transformation on cost data"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					},
					"collapsed": false
				},
				"source": [
					"print(f'fromDate: {fromDate}')\n",
					"print(f'toDate: {toDate}')\n",
					"\n",
					"print(f\"------ From: {fromDate}, To: {toDate} -----------\")\n",
					"\n",
					"print(f\"------ {reportType} -----------\")\n",
					"formatted_to_date = f'{toDate[0:4]}-{toDate[4:6]}-{toDate[6:]}'\n",
					"formatted_to_date = '2021-11-30' if str(formatted_to_date) < '2021-11-30' else formatted_to_date\n",
					"\n",
					"print(f'longToDate: {formatted_to_date}')\n",
					"date_range = fromDate + '-' + toDate\n",
					"print(f'dateRange: {date_range}')\n",
					"\n",
					"cost_source_path = f'abfss://{container}@{storageAccount}.dfs.core.windows.net/exports/monthly/ACMMonthly{reportType}/{date_range}/ACMMonthly{reportType}_{date_range}.parquet'\n",
					"cost_target_path = f'abfss://{container}@{storageAccount}.dfs.core.windows.net/exports/monthly/ACMMonthly{reportType}/{date_range}/Extended_v3_ACMMonthly{reportType}_{date_range}.parquet'\n",
					"\n",
					"# Load subcsription data\n",
					"solum_subscription_path = f'abfss://{container}@{storageAccount}.dfs.core.windows.net/subscriptions/subscriptions_{formatted_to_date}.json'\n",
					"servicenow_subscription_path = f'abfss://{container}@{storageAccount}.dfs.core.windows.net/subscriptions/servicenow/{formatted_to_date}-optimized.parquet'\n",
					"\n",
					"try:\n",
					"    subscription_df = load_and_process_servicenow_subscriptions(servicenow_subscription_path)\n",
					"except:\n",
					"    subscription_df = load_and_process_solum_subscriptions(solum_subscription_path)\n",
					"\n",
					"# Load service file\n",
					"service_path = f'abfss://usage@{storageAccount}.dfs.core.windows.net/services/services-raw.csv'\n",
					"service_csv_options = {'header' : True,\n",
					"                'delimiter' : ';',\n",
					"                'quote' : '\"',\n",
					"                'escape' : '\"'}\n",
					"service_df = spark.read.options(**service_csv_options).csv(service_path)\n",
					"\n",
					"# Load application data\n",
					"application_path = f'abfss://{container}@{storageAccount}.dfs.core.windows.net/applications/ServiceNow-Application-List-Extended.parquet'\n",
					"application_df = load_and_process_applications(application_path)\n",
					"\n",
					"# Process cost data\n",
					"cost_df = spark.read.format('parquet').load(cost_source_path)\n",
					"cost_df = transform_cost_data(cost_df)\n",
					"cost_df = combine_subscriptions_and_applications(cost_df, subscription_df, application_df)\n",
					"cost_df = add_azure_service_information(cost_df, service_df)\n",
					"# write_output_file(cost_df, cost_target_path)\n",
					"print(' ')"
				],
				"execution_count": 104
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from enum import Enum\r\n",
					"class SavingsPlanStatus(Enum):\r\n",
					"    Enabled = \"Enabled\"\r\n",
					"    NotEnabled = \"Not Enabled\"\r\n",
					"    NotSupported = \"Not Supported\"\r\n",
					"\r\n",
					"class AHBStatus(Enum):\r\n",
					"    Enabled = \"Enabled\"\r\n",
					"    NotEnabled = \"Not Enabled\"\r\n",
					"    NotSupported = \"Not Supported\"\r\n",
					""
				],
				"execution_count": 117
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"PROD_OFFER_ID = 'MS-AZR-0017P'"
				],
				"execution_count": 113
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"sp_enabled = (F.col('PricingModel') == 'SavingsPlan') & (F.col('ChargeType') == 'Usage')\r\n",
					"is_ondemand = (F.col('PricingModel') == 'OnDemand') & (F.col('ChargeType') == 'Usage')\r\n",
					"is_vm_compute = (F.col('MeterCategory') == 'Virtual Machines') & ~(F.col('MeterSubCategory').contains('Av1'))\r\n",
					"is_aas_compute = (F.col('MeterCategory') == 'Azure App Service') & (F.col('MeterSubCategory').isin(['Premium v3', 'Isolated v2']))\r\n",
					"is_af_compute = (F.col('MeterCategory') == 'Functions') & (F.col('MeterSubCategory') == 'Premium')\r\n",
					"is_aci_compute = (F.col('MeterCategory') == 'Container Instances')\r\n",
					"is_aca_compute = (F.col('MeterCategory') == 'Azure Container Apps')\r\n",
					"is_sp_eligible = is_vm_compute | is_aas_compute | is_af_compute | is_aci_compute | is_aca_compute\r\n",
					"\r\n",
					"cost_df = cost_df.withColumn('SPStatus', \r\n",
					"    F.when(sp_enabled, SavingsPlanStatus.Enabled.value)\r\n",
					"    .when(is_ondemand & is_sp_eligible, SavingsPlanStatus.NotEnabled.value)\r\n",
					"    .otherwise(SavingsPlanStatus.NotSupported.value)\r\n",
					")"
				],
				"execution_count": 107
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"pricesheet_path = f'abfss://usage@{storageAccount}.dfs.core.windows.net/pricesheet/portal-export/pricesheet-converted/{fromDate}-{toDate}.parquet'\r\n",
					"pricesheet_df = spark.read.format('parquet').load(pricesheet_path)"
				],
				"execution_count": 108
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"sp_pricesheet_df = pricesheet_df.where((F.col('OfferID') == PROD_OFFER_ID) & (F.col('PriceType') == 'SavingsPlan') & (F.col('Term') == 'P3Y'))"
				],
				"execution_count": 109
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"sp_pricesheet_df = sp_pricesheet_df.withColumn('NormalizedUnit', F.regexp_extract('UnitOfMeasure', r'^(\\d+)', 1).cast('integer'))\r\n",
					"sp_pricesheet_df = sp_pricesheet_df.withColumn('NormalizedMemoryFactor', \r\n",
					"    F.when(F.col('UnitOfMeasure').contains('TiB'), 1024) # Standard measure in usage file is GiB --> convertion factor between TiB and Gib is 1024\r\n",
					"    .when(F.col('UnitOfMeasure').contains(\"PiB\"), 1048576) # Standard measure in usage file is GiB --> convertion factor between PiB and Gib is 1048576\r\n",
					"    .when(F.col('UnitOfMeasure').contains(\"TB\"), 1000) # Standard measure in usage file is GB --> convertion factor between TB and Gb is 1000\r\n",
					"    .when(F.col('UnitOfMeasure').contains(\"PB\"), 1000000) # Standard measure in usage file is GB --> convertion factor between PB and Gib is 1000000\r\n",
					"    .otherwise(1)\r\n",
					")\r\n",
					"sp_pricesheet_df = sp_pricesheet_df.withColumn('NormalizedP3YSPUnitPrice', F.col('UnitPrice') / (F.col('NormalizedUnit') * F.col('NormalizedMemoryFactor')))\r\n",
					"sp_pricesheet_df = sp_pricesheet_df.select('PartNumber', 'NormalizedP3YSPUnitPrice')"
				],
				"execution_count": 110
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"cost_df = cost_df.join(sp_pricesheet_df, 'PartNumber', 'left')\r\n",
					"# When cost is classified as eligible to SP, but does not av a P3Y Unit Price associated with it - it should not be eligible to SP\r\n",
					"cost_df = cost_df.withColumn('SPStatus', F.when((F.col('SPStatus') == 'Not Enabled') & F.col('NormalizedP3YSPUnitPrice').isNull(), F.lit(SavingsPlanStatus.NotSupported.value)).otherwise(F.col('SPStatus')))"
				],
				"execution_count": 111
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"is_windows_hub_eligible = (F.col('WindowsAHB') == AHBStatus.Enabled.value) | (F.col('WindowsAHB') == AHBStatus.NotEnabled.value)\r\n",
					"is_sql_hub_eligible = (F.col('SQLAHB') == AHBStatus.Enabled.value) | (F.col('SQLAHB') == AHBStatus.NotEnabled.value)\r\n",
					"\r\n",
					"is_sql_db = (F.col('ResourceId').like('%Microsoft.Sql/servers%')) & (F.col('MeterCategory').like('SQL%'))\r\n",
					"is_sql_mi = (F.col('ResourceId').like('%Microsoft.Sql/managedInstances%')) & (F.col('MeterCategory').like('SQL%'))\r\n",
					"is_sql_vm = (F.col('MeterCategory') == 'Virtual Machines Licenses') & (F.col('MeterSubCategory').like('SQL Server%'))\r\n",
					"\r\n",
					"is_standard_sql_license = F.col('ProductName').like('%Standard%') | F.col('ProductName').like('%General%')\r\n",
					"is_enterprise_sql_license = F.col('ProductName').like('%Enterprise%') | F.col('ProductName').like('%Critical%')\r\n",
					"\r\n",
					"cost_df = cost_df.withColumn('HUBPricesheetJoinKey', \r\n",
					"    F.when(is_windows_hub_eligible,\r\n",
					"        F.concat(\r\n",
					"            F.lit('Windows Server'),\r\n",
					"            F.when(F.col('MeterSubCategory') == 'Windows Server Burst', ' Burst - ').otherwise(' - '), \r\n",
					"            F.col('VCPUs'), \r\n",
					"            F.lit(' vCPU VM License')\r\n",
					"        )\r\n",
					"    )\r\n",
					"    .when(is_sql_hub_eligible & is_sql_mi & is_standard_sql_license, 'SQL Managed Instance General Purpose - SQL License - vCore')\r\n",
					"    .when(is_sql_hub_eligible & is_sql_mi & is_enterprise_sql_license, 'SQL Managed Instance Business Critical - SQL License - vCore')\r\n",
					"    .when(is_sql_hub_eligible & is_sql_db & is_standard_sql_license, 'SQL Database Single/Elastic Pool General Purpose - SQL License - vCore')\r\n",
					"    .when(is_sql_hub_eligible & is_sql_db & is_enterprise_sql_license, 'SQL Database Single/Elastic Pool Business Critical - SQL License - vCore')\r\n",
					"    .when(is_sql_hub_eligible & is_sql_vm & is_standard_sql_license & (F.col('VCPUs') < 5), 'SQL Server Standard - 1-4 vCPU VM License')\r\n",
					"    .when(is_sql_hub_eligible & is_sql_vm & is_enterprise_sql_license & (F.col('VCPUs') < 5), 'SQL Server Enterprise - 1-4 vCPU VM License')\r\n",
					"    .when(is_sql_hub_eligible & is_sql_vm & is_standard_sql_license & (F.col('VCPUs') >= 5), F.concat(F.lit('SQL Server Standard - '), F.col('VCPUs'), F.lit(' vCPU VM License')))\r\n",
					"    .when(is_sql_hub_eligible & is_sql_vm & is_enterprise_sql_license & (F.col('VCPUs') >= 5), F.concat(F.lit('SQL Server Enterprise - '), F.col('VCPUs'), F.lit(' vCPU VM License')))\r\n",
					"    .otherwise(None)\r\n",
					")"
				],
				"execution_count": null
			}
		]
	}
}