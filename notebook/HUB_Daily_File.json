{
	"name": "HUB_Daily_File",
	"properties": {
		"folder": {
			"name": "NotebookInProduction/HUB and RI Savings"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "sprkpool33large",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "112g",
			"driverCores": 16,
			"executorMemory": "112g",
			"executorCores": 16,
			"numExecutors": 1,
			"runAsWorkspaceSystemIdentity": true,
			"conf": {
				"spark.dynamicAllocation.enabled": "true",
				"spark.dynamicAllocation.minExecutors": "1",
				"spark.dynamicAllocation.maxExecutors": "4",
				"spark.autotune.trackingId": "6cba90f2-cac3-4bbf-adf3-a3d63e6c5a39"
			}
		},
		"metadata": {
			"saveOutput": true,
			"enableDebugMode": false,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/13d66f54-0a19-4912-b4f3-54d15897368d/resourceGroups/Synapse/providers/Microsoft.Synapse/workspaces/s037-cost-management/bigDataPools/sprkpool33large",
				"name": "sprkpool33large",
				"type": "Spark",
				"endpoint": "https://s037-cost-management.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/sprkpool33large",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "3.3",
				"nodeCount": 3,
				"cores": 16,
				"memory": 112,
				"automaticScaleJobs": true
			},
			"sessionKeepAliveTimeout": 30
		},
		"cells": [
			{
				"cell_type": "code",
				"metadata": {
					"tags": [
						"parameters"
					]
				},
				"source": [
					"storageAccount = 's037costmgmt'"
				],
				"execution_count": 5
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"from datetime import timedelta, datetime\n",
					"from dateutil.relativedelta import relativedelta\n",
					"import calendar\n",
					"import json\n",
					"import pandas as pd\n",
					"from notebookutils import mssparkutils\n",
					"from azure.storage.blob import BlobServiceClient\n",
					"import pyspark.sql.functions as F"
				],
				"execution_count": 6
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"KEY_VAULT_NAME = 'acm-toolkit-kv'\r\n",
					"LINKED_SERVICE_NAME = 'ACM_Toolkit_kv'"
				],
				"execution_count": 7
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"hubAutomationConnectionString = mssparkutils.credentials.getSecret(KEY_VAULT_NAME , 'hubautomation-sa-connectionstring', LINKED_SERVICE_NAME)"
				],
				"execution_count": 8
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"def get_dates_last_month():\r\n",
					"    last_month_start = (datetime.now() - relativedelta(months=1)).strftime('%Y%m01')\r\n",
					"    today = datetime.now()\r\n",
					"    first = today.replace(day=1)\r\n",
					"    res = first - timedelta(days=1)\r\n",
					"    last_month_end = res.date().strftime('%Y%m%d')\r\n",
					"    return last_month_start, last_month_end"
				],
				"execution_count": 9
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"end_date = (datetime.now().strftime('%Y-%m-%d'))\r\n",
					"vm_start_date = (datetime.now() - timedelta(days=2)).strftime('%Y-%m-%d')\r\n",
					"sql_start_date = (datetime.now() - timedelta(days=3)).strftime('%Y-%m-%d')"
				],
				"execution_count": 10
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"daily_path = f'abfss://usage@{storageAccount}.dfs.core.windows.net/exports/daily/ACMDailyActualCost/ACMDailyActualCost.parquet'\r\n",
					"daily_df = spark.read.format('parquet').load(daily_path)\r\n",
					"\r\n",
					"last_month_start, last_month_end = get_dates_last_month()\r\n",
					"\r\n",
					"monthly_path = f'abfss://usage@{storageAccount}.dfs.core.windows.net/exports/monthly/ACMMonthlyActualCost/{last_month_start}-{last_month_end}/ACMMonthlyActualCost_{last_month_start}-{last_month_end}.parquet'\r\n",
					"monthly_df = spark.read.format('parquet').load(monthly_path)\r\n",
					"\r\n",
					"cost_df = daily_df.union(monthly_df)"
				],
				"execution_count": 11
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Write pricesheet to HUBAutomation"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"pricesheet_source_path = f'abfss://usage@{storageAccount}.dfs.core.windows.net/pricesheet/portal-export/pricesheet-latest'\r\n",
					"pricesheet_target_path = 'abfss://win-activity@hubautomation.dfs.core.windows.net/usage_details/pricesheet.csv'\r\n",
					"\r\n",
					"print('Loading the latest pricesheet from source parquet')\r\n",
					"pricesheet = spark.read.format('parquet').load(pricesheet_source_path)\r\n",
					"print('Writing pricesheet to destination csv file')\r\n",
					"pricesheet.toPandas().to_csv(pricesheet_target_path, index=False)"
				],
				"execution_count": 12
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Load cost data"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"vm_cost_df = cost_df.where(F.col('Date') >= vm_start_date)\r\n",
					"sql_cost_df = cost_df.where(F.col('Date') == sql_start_date)"
				],
				"execution_count": 13
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Compute VM related cost"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"print(vm_cost_df.count())\n",
					"\n",
					"is_vm_cost = ((F.col('ResourceId').contains('/virtualMachines/')) | (F.col('ResourceId').contains('/virtualMachineScaleSets/'))) \\\n",
					"    & ((F.col('MeterSubCategory').contains('Windows')) | (F.col('ServiceInfo2').contains('Wubdiws Server BYOL')))\n",
					"\n",
					"vm_cost_df = vm_cost_df.where(is_vm_cost)\n",
					"\n",
					"vm_columns_to_keep = ['SubscriptionId', 'SubscriptionName','Date','ResourceGroup', 'ResourceName', 'ResourceId', \n",
					"    'MeterCategory', 'MeterSubCategory', 'MeterName','UnitOfMeasure','Quantity','UnitPrice','EffectivePrice',\n",
					"    'CostInBillingCurrency', 'ServiceInfo2', 'PartNumber', 'AdditionalInfo']\n",
					"\n",
					"vm_cost_df = vm_cost_df.select(*vm_columns_to_keep)\n",
					"\n",
					"print(vm_cost_df.count())"
				],
				"execution_count": 14
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Fetch SQL config MeterSubCategories"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"blob_service_client = BlobServiceClient.from_connection_string(hubAutomationConnectionString)\r\n",
					"\r\n",
					"# get a reference to the blob container and file\r\n",
					"container_name = 'sql-config'\r\n",
					"blob_name = 'config.json'\r\n",
					"container_client = blob_service_client.get_container_client(container_name)\r\n",
					"blob_client = container_client.get_blob_client(blob_name)\r\n",
					"\r\n",
					"# download the blob content as a string\r\n",
					"blob_content = blob_client.download_blob().content_as_text()\r\n",
					"\r\n",
					"# parse the JSON string into a Python dictionary\r\n",
					"sql_config = json.loads(blob_content)\r\n",
					"\r\n",
					"sql_metersubcategory_array = sql_config['MeterSubCategory']\r\n",
					"print(sql_metersubcategory_array)"
				],
				"execution_count": 15
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Compute SQL related cost"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"sql_columns_to_keep = ['SubscriptionId', 'SubscriptionName','Date','ResourceGroup', 'ResourceName', 'ResourceId', \r\n",
					"    'MeterCategory', 'MeterSubCategory', 'MeterName','UnitOfMeasure','Quantity','UnitPrice','EffectivePrice',\r\n",
					"    'CostInBillingCurrency', 'ServiceInfo2', 'PartNumber', 'ProductName', 'AdditionalInfo']\r\n",
					"\r\n",
					"sql_cost_df = sql_cost_df.select(*sql_columns_to_keep)"
				],
				"execution_count": 16
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"print(sql_cost_df.count())\r\n",
					"sql_cost_df = sql_cost_df.where(F.col('MeterSubCategory').isin(sql_metersubcategory_array))\r\n",
					"print(sql_cost_df.count())"
				],
				"execution_count": 17
			},
			{
				"cell_type": "markdown",
				"metadata": {
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"## Write result to optimized container"
				]
			},
			{
				"cell_type": "code",
				"metadata": {
					"jupyter": {
						"source_hidden": false,
						"outputs_hidden": false
					},
					"nteract": {
						"transient": {
							"deleting": false
						}
					}
				},
				"source": [
					"win_output_path = 'abfss://win-activity@hubautomation.dfs.core.windows.net/usage_details/'\n",
					"sql_output_path = 'abfss://sql-activity@hubautomation.dfs.core.windows.net/usage_details/'\n",
					"\n",
					"# Write VM usage details\n",
					"print('Writing DataFrame to parquet file: ', win_output_path + 'vm_' + end_date + '.csv')\n",
					"vm_cost_df.toPandas().to_csv(win_output_path + 'vm_' + end_date + '.csv')\n",
					"\n",
					"print('Writing DataFrame to parquet file: ', win_output_path + 'vm_today.csv')\n",
					"vm_cost_df.toPandas().to_csv(win_output_path + 'vm_today.csv')\n",
					"\n",
					"# Write SQL usage details\n",
					"print('Writing DataFrame to parquet file: ', sql_output_path + 'sql_' + end_date + '.csv')\n",
					"sql_cost_df.toPandas().to_csv(sql_output_path + 'sql_' + end_date + '.csv')\n",
					"\n",
					"print('Writing DataFrame to parquet file: ', sql_output_path + 'sql_today.csv')\n",
					"sql_cost_df.toPandas().to_csv(sql_output_path + 'sql_today.csv')\n",
					"\n",
					"print('File write complete.')"
				],
				"execution_count": 22
			}
		]
	}
}